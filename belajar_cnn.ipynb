{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOChN8NzbT6sNWF+JoIFcYx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fauzanismara/belajarpenelitian/blob/main/belajar_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "Rh7fRRQ_v0fM",
        "outputId": "16552e94-5cdb-4f18-8161-14d1b4dc99a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1653 images belonging to 10 classes.\n",
            "Found 409 images belonging to 10 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 602ms/step - accuracy: 0.1152 - loss: 2.3621 - val_accuracy: 0.1369 - val_loss: 2.2354\n",
            "Epoch 2/5\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 601ms/step - accuracy: 0.3401 - loss: 1.8346 - val_accuracy: 0.5599 - val_loss: 1.1935\n",
            "Epoch 3/5\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 604ms/step - accuracy: 0.7963 - loss: 0.5812 - val_accuracy: 0.6333 - val_loss: 1.1336\n",
            "Epoch 4/5\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 592ms/step - accuracy: 0.8825 - loss: 0.3503 - val_accuracy: 0.7115 - val_loss: 0.9342\n",
            "Epoch 5/5\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 646ms/step - accuracy: 0.9273 - loss: 0.2348 - val_accuracy: 0.6577 - val_loss: 1.0461\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Sequential' object has no attribute 'to'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1093995506.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m#savemodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mmodel_json\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model.json\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'to'"
          ]
        }
      ],
      "source": [
        "#Import Library\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "\n",
        "#Prepare Data\n",
        "data_dir = 'datasetASL/Dataset'\n",
        "target_size = (100,100)\n",
        "classes = 10\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   zoom_range=0.1,\n",
        "                                   horizontal_flip=False,\n",
        "                                   validation_split=0.2)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(data_dir, target_size=target_size,\n",
        "                                              shuffle = True,\n",
        "                                              batch_size = 32,\n",
        "                                              color_mode ='rgb',\n",
        "                                              class_mode = 'categorical',\n",
        "                                              subset='training')\n",
        "\n",
        "val_gen = train_datagen.flow_from_directory(data_dir,target_size=target_size,\n",
        "                                            batch_size=32,\n",
        "                                            color_mode='rgb',\n",
        "                                            class_mode='categorical',\n",
        "                                            subset='validation')\n",
        "\n",
        "\n",
        "\n",
        "#Create Model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32,kernel_size=3,strides=1,activation='relu', padding='same', input_shape = (100,100,3)))\n",
        "model.add(MaxPooling2D(pool_size=(3,3),strides=2))\n",
        "\n",
        "model.add(Conv2D(32,kernel_size=3,strides=1,activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
        "\n",
        "model.add(Conv2D(32,kernel_size=3,strides=1,activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
        "\n",
        "model.add(Conv2D(32,kernel_size=3,strides=1,activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=1))\n",
        "\n",
        "#flatten\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0,5))\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dense(classes,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "#compile model\n",
        "model.fit(\n",
        "    train_gen,\n",
        "    epochs=5,\n",
        "    validation_data=val_gen\n",
        ")\n",
        "\n",
        "\n",
        "#savemodel\n",
        "\n",
        "model_json=model.to.json()\n",
        "with open(\"model.json\",\"w\") as file:\n",
        "  file.write(model_json)\n",
        "model.save_wights(\"model.h5\")\n",
        "print(\"Succesful model is saved !\")\n"
      ]
    }
  ]
}